import networkx as nx
import community as community_louvain
import matplotlib.pyplot as plt
import pandas as pd
import numpy as np
from termcolor import colored, cprint
from typing import NamedTuple
from dataclasses import dataclass, fields
from collections import Counter
from collections import defaultdict

# Installing infomap using the default g++14 compiler on my system, the script excited with c++ error.
# So I had to manually force the usage of g++12 for installation with the command below.
# CC=/usr/bin/gcc-12 CXX=/usr/bin/g++-12 pip install infomap --no-cache-dir --force-reinstall
# from infomap import Infomap
import tqdm

@dataclass()
class Graphs():
    """ 
    A data class that contains all the graphs and data generated by the generate_graphs() method

    ...

    Attributes
    ----------
    full : nx.DiGraph
        Nodes are subreddits, links are directed and represent hyperlinks. The weight represents the number of hyperlinks
        from one subreddit to another
    positive : nx.DiGraph
        Nodes are subreddits, links are directed and represent hyperlinks. The weight represents the number of positive
        minus the number of negative hyperlinks from one subreddit to another. We do not add links with weight < 1
    negative : nx.DiGraph
        Nodes are subreddits, links are directed and represent hyperlinks. The weight represents the number of negative
        minus the number of positive hyperlinks from one subreddit to another. We do not add links with weight < 1
    """
    full: nx.DiGraph
    positive: nx.DiGraph
    negative: nx.DiGraph

    def __iter__(self):
        yield self.full
        yield self.positive
        yield self.negative

    def withNames(self):
        return [(self.full, "G_full"), (self.positive, "G_positive"), (self.negative, "G_negative")]
    
    def exportAsGexf(self):
        for G, name in self.withNames():
            nx.write_gexf(G, f"{name}.gexf")
    
    def apply(self, func):
        result = []
        for G in self:
            result.append(func(G))
        return result

def print_connected(G: nx.DiGraph) -> float:
    comps = sorted(nx.connected_components(G.to_undirected(as_view=True)), key=len, reverse=True)
        
    print(f"{len(comps[0])} out of {len(G)} nodes({(len(comps[0]) / len(G))*100:2f}%) are part of the main subgraph.") 


# def infomap_community_detection(G: nx.DiGraph) -> dict:
#     """ Run the infomap community detection algorithm on graph G. Return a dict[nodeID, communityID]

#     Parameters
#     ----------
#     G : networkx.DiGraph
#         The subreddit interaction graph.

#     Returns
#     -------
#     communities : dict[str, int]
#         Returns the dict[nodeID, communityID]
#     """

#     # Necessary mappings as addlink expects integer ids
#     node_to_id = {node: i for i, node in enumerate(G.nodes())}
#     id_to_node = {i: node for node, i in node_to_id.items()}

#     im = Infomap(directed=True)
#     for u, v, data in G.edges(data = True):
#         im.addLink(node_to_id[u], node_to_id[v], data["weight"])
#     im.run()

#     # Get communities
#     res = {}
#     for node in im.tree:
#         if node.is_leaf:
#             if id_to_node[node.node_id] in res:
#                 cprint(f"Node {id_to_node[node.node_id]} who was attributed to community {res[id_to_node[node.node_id]]} is now attributed to community {node.module_id}.", "red")
#             res[id_to_node[node.node_id]] = node.module_id
#     return res

def extract_main_components(gs: Graphs) -> Graphs:
    """ Create a new Graphs object where the only the nodes connected to the main component are kept.

    Parameters
    ----------
    gs : Graphs
        The Graphs object

    Returns
    -------
    new_gs : Graphs
        Returns a new Graphs object where only the nodes connected to the main component are kept.
    """
    graphs: list[nx.DiGraph] = []
    for G in gs:

        # Find largest connected component
        main_nodes = max(nx.connected_components(G.to_undirected(as_view=True)), key=len)

        # Create a new graph with only those nodes
        G_main = G.subgraph(main_nodes).copy()

        graphs.append(G_main)
    
    return Graphs(graphs[0], graphs[1], graphs[2])


def generate_graphs(df: pd.DataFrame) -> Graphs:
    """ Given the reddit dataset as input, generate the 3 directed graphs and return them as a Graphs object

    Parameters
    ----------
    df : pd.DataFrame
        The subreddit dataset

    Returns
    -------
    gs : Graphs
        Returns an instance of the Graphs class
    """
    cprint("Generate the graphs", color="green")
    gs = Graphs(nx.DiGraph(), nx.DiGraph(), nx.DiGraph())

    # Add the links
    agg = df.groupby(["SOURCE_SUBREDDIT", "TARGET_SUBREDDIT"])["LINK_SENTIMENT"].agg(["sum", "count"]).reset_index()
    agg["inverted_sum"] = -agg["sum"]
    for _, row in agg.iterrows():
        gs.full.add_edge(
            row["SOURCE_SUBREDDIT"],
            row["TARGET_SUBREDDIT"],
            weight=row["count"]
        )
        if row["inverted_sum"] > 0:
            gs.negative.add_edge(
                row["SOURCE_SUBREDDIT"],
                row["TARGET_SUBREDDIT"],
                weight=row["inverted_sum"]
            )
        if row["sum"] > 0:
            gs.positive.add_edge(
                row["SOURCE_SUBREDDIT"],
                row["TARGET_SUBREDDIT"],
                weight=row["sum"]
            )

    # Run the infomap community detection algorithms
    # as louvain algorithm does not work on directed graphs.
    # cprint("Run infomap on the graphs", color="green")
    # infomap_full = infomap_community_detection(gs.full)
    # infomap_pos = infomap_community_detection(gs.positive)
    # infomap_neg = infomap_community_detection(gs.negative)
    cprint("Run louvain on the graphs", color="green")
    louvain_full = community_louvain.best_partition(gs.full.to_undirected())
    louvain_pos = community_louvain.best_partition(gs.positive.to_undirected())
    louvain_neg = community_louvain.best_partition(gs.negative.to_undirected())
    for G in tqdm.tqdm(gs):
        # nx.set_node_attributes(G, infomap_full, "infomap_full")
        # nx.set_node_attributes(G, infomap_pos, "infomap_positive")
        # nx.set_node_attributes(G, infomap_neg, "infomap_negative")
        nx.set_node_attributes(G, louvain_full, "louvain_full")
        nx.set_node_attributes(G, louvain_pos, "louvain_positive")
        nx.set_node_attributes(G, louvain_neg, "louvain_negative")

    # Add an the attributes to the nodes
    cprint("Add the attributes to the graphs", color="green")
    agg = df.groupby(["SOURCE_SUBREDDIT"])["LINK_SENTIMENT"].agg(["sum", "count"]).reset_index()
    for _, row in agg.iterrows():
        for G in gs:
            subreddit = row["SOURCE_SUBREDDIT"]
            if subreddit not in G:
                G.add_node(subreddit)
            G.nodes[subreddit]["num_posts"] = row["count"]
            G.nodes[subreddit]["positivity"] = row["sum"]

    cprint("Export the graphs", color="green")
    for G, name in gs.withNames():
        print(f"{name}: nb nodes: {G.number_of_nodes()}")
        print(f"{name}: nb edges: {G.number_of_edges()}")

    return gs


def print_top_degrees(nodes: list[str], gs: Graphs):
    """ For the nodes given as input, print the top5 nodes that attack the most and that are the most
    attacked, in absolute numbers and proportionaly.

    Parameters
    ----------
    nodes : list[str]
        A list of NodeIDs
    gs : Graphs
        A graphs object
    """
    neg_weighted_in_degree = dict(gs.negative.in_degree(weight='weight'))
    neg_weighted_out_degree = dict(gs.negative.out_degree(weight='weight'))
    full_weighted_in_degree = dict(gs.full.in_degree(weight='weight'))
    full_weighted_out_degree = dict(gs.full.out_degree(weight='weight'))

    top_nodes_in_degree = sorted(nodes, key=lambda n: neg_weighted_in_degree.get(n, 0), reverse=True)[:5]
    top_nodes_out_degree = sorted(nodes, key=lambda n: neg_weighted_out_degree.get(n, 0), reverse=True)[:5]
    
    cprint(f"Nodes that attack the most (highest out degree):", color="blue")
    for node in top_nodes_out_degree:
        print(f"{node:<22}: {neg_weighted_out_degree.get(node, 0):>3} out of {full_weighted_out_degree.get(node, 0):>6,} "
              f"hyperlinks ({(neg_weighted_out_degree.get(node, 0)/full_weighted_out_degree.get(node, 0))*100:.2f}%)")
    cprint(f"Nodes that are the most attacked (highest in degree):", color="blue")
    for node in top_nodes_in_degree:
        print(f"{node:<22}: {neg_weighted_in_degree.get(node, 0):>3} out of {full_weighted_in_degree.get(node, 0):>6,} "
              f"hyperlinks ({(neg_weighted_in_degree.get(node, 0)/full_weighted_in_degree.get(node, 0))*100:.2f}%)")
    
    top_nodes_in_degree = sorted(nodes, key=lambda n: (neg_weighted_in_degree[n] / full_weighted_in_degree[n]) if full_weighted_in_degree[n] > 20 else 0, reverse=True)[:5]
    top_nodes_out_degree = sorted(nodes, key=lambda n: (neg_weighted_out_degree[n] / full_weighted_out_degree[n]) if full_weighted_out_degree[n] > 20 else 0, reverse=True)[:5]
    
    cprint(f"Nodes with a degree > 20 that have the highest attack vs cite ratio:", color="blue")
    for node in top_nodes_out_degree:
        print(f"{node:<22}: {neg_weighted_out_degree.get(node, 0):>3} out of {full_weighted_out_degree.get(node, 0):>6,} "
              f"hyperlinks ({(neg_weighted_out_degree.get(node, 0)/full_weighted_out_degree.get(node, 0))*100:.2f}%)")
    cprint(f"Nodes with a degree > 20 that have the highest being attacked vs being cited ratio :", color="blue")
    for node in top_nodes_in_degree:
        print(f"{node:<22}: {neg_weighted_in_degree.get(node, 0):>3} out of {full_weighted_in_degree.get(node, 0):>6,} "
              f"hyperlinks ({(neg_weighted_in_degree.get(node, 0)/full_weighted_in_degree.get(node, 0))*100:.2f}%)")


def get_sorted_negative_louvain_Communities(gs: Graphs) -> list[tuple[str, list[str]]]:
    """ Get the louvain communities of the negative Graph sorted by size of the communities

    Parameters
    ----------
    gs : Graphs
        A Graphs object

    Returns
    -------
    communities : list[tuple[str, list[str]]]
        Returns a list of tuple[CommunityID, list[NodeID]]
    """
    communities: defaultdict[str, list[str]] = defaultdict(list)

    for node, comm in nx.get_node_attributes(gs.negative, "louvain_negative").items():
        communities[f"Community with id {comm}"].append(node)
    communities["Graph of negative hyperlinks"] = gs.negative.nodes()

    sorted_communities = sorted(communities.items(), key=lambda item: len(item[1]), reverse=True)

    return sorted_communities
     
def plot_degree_distribution(gs: Graphs):
    """ Print a degree distribution graph

    Parameters
    ----------
    gs : Graphs
        A graphs object
    """
    neg_weighted_in_degree = dict(gs.negative.in_degree(weight='weight'))
    neg_weighted_out_degree = dict(gs.negative.out_degree(weight='weight'))
    full_weighted_in_degree = dict(gs.full.in_degree(weight='weight'))
    full_weighted_out_degree = dict(gs.full.out_degree(weight='weight'))
    sorted_communities = get_sorted_negative_louvain_Communities(gs)


    plt.figure(figsize=(8,6))
    # Print top 5 nodes by weighted degree for each community
    for name, nodes in [("Full Graph", gs.full.nodes())] + sorted_communities[:2]:
        cprint(f"{name} ({len(nodes)} nodes)", "green")

        # In degrees
        degrees = [neg_weighted_in_degree.get(node, 0) for node in nodes]
        if name == "Full Graph":
            degrees = [full_weighted_in_degree.get(node, 0) for node in nodes]
        degree_counts = Counter(degrees)
        x = sorted(degree_counts.keys())
        y = [degree_counts[d] for d in x]
        plt.plot(x, y, marker='o', linestyle='-', label=f'{name} (in)')

        # Out degrees
        degrees = [neg_weighted_out_degree.get(node, 0) for node in nodes]
        if name == "Full Graph":
            degrees = [full_weighted_out_degree.get(node, 0) for node in nodes]
        degree_counts = Counter(degrees)
        x = sorted(degree_counts.keys())
        y = [degree_counts[d] for d in x]
        plt.plot(x, y, marker='o', linestyle='-', label=f'{name} (out)')
        
    # Logâ€“log scale
    plt.xscale('log')
    plt.yscale('log')

    plt.xlabel('Weighted degree (log scale)')
    plt.ylabel('Number of subreddits (log scale)')
    plt.title('Degree distribution per community')
    plt.legend()
    plt.tight_layout()
    plt.show()